In this talk, i report on the general idea of database-driven network generation, it's use for bioremediation, and the problems arising from inconsistent data.

Bioremediation is a natural occuring process, which is especially important for soil, which is contamined with chemical pollutants.
My goal was to examine, whether and how we can use computer programs fed from online databases to predict stategies how to faciliate certain degradation pathways.
Generally, those predictions are made with methods which act on network representations of metabolisms of calls, mainly flux balance analysis, but also other graph theoretic approaches.

In theory, such approaches allow the prediction of feasible organism consortia for biological treatment of specific envronmental situations. In practice, they require reaction data, which only is of limited accuracy in online databases. Inconsistent data sets often hinder application of feasible methods.

Thus, i examined the KEGG, a prominent example of such online databases, spotting on inconsistencies and remediaton strategies, wich will presented in a condensed form.
And i will discuss, strategies remain feasible taking the shortcomings of such databases into account.